{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a58b0e3",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0257bd44",
   "metadata": {},
   "source": [
    "#### What is clustering?\n",
    "\n",
    "Clustering is the task of dividing the population or data points into a number of groups such that data points in the same groups are more similar to other data points in the same group and dissimilar to the data points in other groups. It is basically a collection of objects on the basis of similarity and dissimilarity between them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed769ba",
   "metadata": {},
   "source": [
    "#### How to identify the optimal number of clusters?\n",
    "\n",
    "Using the \"Elbow method\": Plot the error as a function number of clusters. Choose the number of cluster after which the error decreases in a linear manner. Sum of square error or inertia is a well-known metric used for this purpose. For a reference plot see: https://media.geeksforgeeks.org/wp-content/uploads/20230418184707/download-(8).png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678ea5e5",
   "metadata": {},
   "source": [
    "#### What is the Bias-variance trade-off?\n",
    "\n",
    "As the number of parameters in a model increases, the bias of the fitted model goes down but the variance of the fitted model goes up\n",
    "\n",
    "On the other hand, if the number of parameters in a model is kept low, the variance in the model might not be much but the bias of the model would be high. \n",
    "\n",
    "The gives rise to a U-shaped curve for the model error as a function of the number of parameters. The trade-off in the variance and bias as the number of model parameters are varied is known as the bias-variance trade-off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cce5fd0",
   "metadata": {},
   "source": [
    "#### What is feature engineering? How does it affect the model’s performance? \n",
    "\n",
    "Feature engineering refers to developing some new features by using existing features. Feature engineering can help imporve model performace by 1) increasing accuracy 2) reducing model size 3) Reduce input features by clubbing them together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5215fb3",
   "metadata": {},
   "source": [
    "#### What is overfitting and how can we avoid it?\n",
    "\n",
    "Overfitting happens when the model learns patterns as well as the noises present in the data this leads to high performance on the training data but very low performance for data that the model has not seen earlier. To avoid overfitting there are multiple methods that we can use:\n",
    "\n",
    "1. Early stopping of the model’s training in case of validation training stops increasing but the training keeps going on.\n",
    "2. Using regularization methods like L1 or L2 regularization which is used to penalize the model’s weights to avoid overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6818bd7",
   "metadata": {},
   "source": [
    "#### What is early stopping?\n",
    "\n",
    "In Early Stopping, we stop training the model when the performance of the model on the validation set is getting worse\n",
    "\n",
    "By plotting the error on the training dataset and the validation dataset together, both the errors decrease with a number of iterations until the point where the model starts to overfit. After this point, the training error still decreases but the validation error increases. So, even if training is continued after this point, early stopping essentially returns the set of parameters that were used at this point and so is equivalent to stopping training at that point. So, the final parameters returned will enable the model to have low variance and better generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b08f26",
   "metadata": {},
   "source": [
    "#### What is k-fold cross validation?\n",
    "\n",
    "K-fold cross validation is used for estimating prediction error in a given model.\n",
    "\n",
    "The dataset is divided into k subsets or folds. The model is trained and evaluated k times, using a different fold as the validation set each time. Performance metrics from each fold are averaged to estimate the model’s generalization performance. This method aids in model assessment, selection, and hyperparameter tuning, providing a more reliable measure of a model’s effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f701e52e",
   "metadata": {},
   "source": [
    "#### What is the difference between the k-means and k-means++ algorithms?\n",
    "\n",
    "One disadvantage of the K-means algorithm is that it is sensitive to the initialization of the centroids or the mean points. So, if a centroid is initialized to be a “far-off” point, it might just end up with no points associated with it, and at the same time, more than one cluster might end up linked with a single centroid. Similarly, more than one centroid might be initialized into the same cluster resulting in poor clustering.\n",
    "\n",
    "To overcome the above-mentioned drawback we use K-means++. This algorithm ensures a smarter initialization of the centroids and improves the quality of the clustering. Apart from initialization, the rest of the algorithm is the same as the standard K-means algorithm. That is K-means++ is the standard K-means algorithm coupled with a smarter initialization of the centroids.\n",
    "\n",
    "The steps involved are: \n",
    " \n",
    "1. Randomly select the first centroid from the data points.\n",
    "2. For each data point compute its distance from the nearest, previously chosen centroid.\n",
    "3. Select the next centroid from the data points such that the probability of choosing a point as centroid is directly proportional to its distance from the nearest, previously chosen centroid. (i.e. the point having maximum distance from the nearest centroid is most likely to be selected next as a centroid)\n",
    "4. Repeat steps 2 and 3 until k centroids have been sampled\n",
    "\n",
    "Reference: https://www.geeksforgeeks.org/ml-k-means-algorithm/#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353dd08b",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198df06c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74cff584",
   "metadata": {},
   "source": [
    "# General"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45da701d",
   "metadata": {},
   "source": [
    "#### What is a garbage collector?\n",
    "\n",
    "Garbage collector (GC) is a form of automatic memory management.\n",
    "\n",
    "The GC attempts to reclaim memory which was allocated by the program but is no longer referenced.\n",
    "\n",
    "Advantages of GC:\n",
    "1. Frees developers from having to manually release memory\n",
    "2. Avoids memory leaks, in which a program fails to free memory occupied by objects that have become unrechable.\n",
    "\n",
    "Disadvantages of GC:\n",
    "1. GC uses computing resources to decide which memory to free, which impair performance\n",
    "2. Unpredictability in memory management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4654bc6f",
   "metadata": {},
   "source": [
    "#### What is the difference between a CPU and a GPU?\n",
    "\n",
    "The main difference is that CPU is designed to handle a wide-range of tasks quickly, but are limited in the concurrency of tasks.\n",
    "\n",
    "Generally speaking, GPUs are much faster than CPUs at highly parallel simple tasks like multiplying big matrices.\n",
    "\n",
    "GPUs are designed to make rendering of 3D images more efficient."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
